{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a89d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "import os\n",
    "import threading\n",
    "import multiprocessing.pool\n",
    "from functools import partial\n",
    "from PIL import Image as pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "from ipynb.fs.full.CNN_LSTM_Model import *\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (240, 320)\n",
    "FRAMES_PER_STEP = 4\n",
    "BATCH_SIZE = 8\n",
    "DATA_FORMAT = 'channels_last'\n",
    "DROPOUT = 0.7\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2dab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(object):\n",
    "    \n",
    "    def __init__(self, data_format = None):\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format()\n",
    "            if data_format not in {'channels_last', 'channels_first'}:\n",
    "                raise ValueError('`data_format` should be `\"channels_last\"` (channel after row and '\n",
    "                             'column) or `\"channels_first\"` (channel before row and column). '\n",
    "                             'Received arg: ', data_format)\n",
    "            self.data_format = data_format\n",
    "            # need to deal with data_format\n",
    "            print('Supported image data format')\n",
    "            if data_format == DATA_FORMAT:\n",
    "                self.channel_axis = 3\n",
    "                self.row_axis = 1\n",
    "                self.col_axis = 2\n",
    "                \n",
    "    def flow(self, x, y = None, batch_size = BATCH_SIZE, seed = None):\n",
    "        return NumpyArrayIterator(x,\n",
    "                                  y,\n",
    "                                  self,\n",
    "                                  seed = seed,\n",
    "                                  data_format = self.data_format)\n",
    "        \n",
    "    \n",
    "    def flow_from_directory(self, directory, \n",
    "                            target_size= IMG_SIZE, \n",
    "                            frames_per_step = FRAMES_PER_STEP, \n",
    "                            batch_size = BATCH_SIZE, \n",
    "                            seed=None):\n",
    "        return DirectoryIterator(directory, \n",
    "                                 self, \n",
    "                                 target_size = target_size, \n",
    "                                 frames_per_step = frames_per_step,\n",
    "                                 data_format = self.data_format,\n",
    "                                 batch_size = batch_size,\n",
    "                                 seed = seed)\n",
    "    \n",
    "    def chnage_dims(self, image):\n",
    "        \"\"\"Expands dimentions of a batch of images\"\"\"\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        return image\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453cf40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterator(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 n,\n",
    "                 batch_size, \n",
    "                 frames_per_step,\n",
    "                 seed):\n",
    "        self.n = n\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_index = 0\n",
    "        self.total_batches_seen = 0\n",
    "        self.lock = threading.Lock()\n",
    "        self.index_generator = self._flow_index(n, batch_size, frames_per_step, seed)\n",
    "        \n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "        \n",
    "    def _flow_index(self, n, batch_size = BATCH_SIZE, frames_per_step = FRAMES_PER_STEP, shuffle = False, seed = None):\n",
    "        # Ensure self.batch_index = 0\n",
    "        self.reset()\n",
    "        while True:\n",
    "            if seed is not None:\n",
    "                np.random.seed(seed + self.total_batches_seen)\n",
    "            if self.batch_index == 0:\n",
    "                index_array = np.arange(n)\n",
    "                if shuffle:\n",
    "                    index_array = np.arange.permutation(n)\n",
    "            current_index = (self.batch_index * batch_size * frames_per_step) % n\n",
    "            if n > current_index + batch_size * frames_per_step:\n",
    "                current_batch_size = batch_size * frames_per_step\n",
    "                #current_batch_size = batch_size \n",
    "                self.batch_index += 1\n",
    "            else:\n",
    "                current_batch_size = n - current_index\n",
    "                self.batch_index = 0\n",
    "            self.total_batches_seen += 1\n",
    "            yield(index_array[current_index: current_index + current_batch_size],\n",
    "                  current_index,\n",
    "                  batch_size)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        # needed if you want to do something like:\n",
    "        # for x, y in data_gen.flow(...):\n",
    "        return self\n",
    "    def __next__(self, *args, ** kwargs):\n",
    "        return self.next(*args, **kwargs)\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed7e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayIterator(Iterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 x, \n",
    "                 y,\n",
    "                 batch_size = BATCH_SIZE,\n",
    "                 shuffle = True,\n",
    "                 seed = None,\n",
    "                 data_format = None):\n",
    "        if y is not None and len(x) != len(x):\n",
    "            raise ValueError('X (images tensor) and y (labels) '\n",
    "                             'should have the same length. '\n",
    "                             'Found: X.shape = %s, y.shape = %s' %\n",
    "                             (np.asarray(x).shape, np.asarray(y).shape))\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format()\n",
    "        # for x data(input image) need to recheck about data_format . it requires or needs to totaly remove\n",
    "        # when we deal with input and ground /// needs to re visit.\n",
    "        # currently we use single data_format // if need to add data_format for y also.\n",
    "        \n",
    "        self.x = np.asarray(x, dtype = K.floatx())\n",
    "        \n",
    "        if self.x.ndim != 4:\n",
    "            raise ValueError('Input data in `NumpyArrayIterator` '\n",
    "                             'should have rank 4. You passed an array '\n",
    "                             'with shape', self.x.shape)\n",
    "            \n",
    "        channels_axis = 3 if data_format == DATA_FORMAT else 1\n",
    "        \n",
    "        if self.x.shape[channels_axis] not in {1, 3, 4}:\n",
    "            warnings.warn('NumpyArrayIterator is set to use the '\n",
    "                          'data format convention \"' + data_format + '\" '\n",
    "                          '(channels on axis ' +\n",
    "                          str(channels_axis) + '), i.e. expected '\n",
    "                          'either 1, 3 or 4 channels on axis ' +\n",
    "                          str(channels_axis) + '. '\n",
    "                          'However, it was passed an array with shape ' + str(self.x.shape) +\n",
    "                          ' (' + str(self.x.shape[channels_axis]) + ' channels).')\n",
    "            \n",
    "            \n",
    "        self.y = np.asarray(y, dtype = K.floatx())\n",
    "        \n",
    "        if self.y.ndim != 4:\n",
    "            raise ValueError('Input data in `NumpyArrayIterator` '\n",
    "                             'should have rank 4. You passed an array '\n",
    "                             'with shape', self.y.shape)\n",
    "            \n",
    "        channels_axis = 3 if data_format == DATA_FORMAT else 1\n",
    "        \n",
    "        if self.y.shape[channels_axis] not in {1, 3, 4}:\n",
    "            warnings.warn('NumpyArrayIterator is set to use the '\n",
    "                          'data format convention \"' + data_format + '\" '\n",
    "                          '(channels on axis ' +\n",
    "                          str(channels_axis) + '), i.e. expected '\n",
    "                          'either 1, 3 or 4 channels on axis ' +\n",
    "                          str(channels_axis) + '. '\n",
    "                          'However, it was passed an array with shape ' + str(self.x.shape) +\n",
    "                          ' (' + str(self.y.shape[channels_axis]) + ' channels).')\n",
    "            \n",
    "        self.image_data_generotor = image_data_generotor\n",
    "        self.data_format = data_format\n",
    "        super(NumpyArrayIterator, self).__init(x.shape[0],\n",
    "                                               batch_size,\n",
    "                                               shuffle,\n",
    "                                               seed)\n",
    "    def next(self):\n",
    "        # keeps under lock only the mechanism which advances, so indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "            \n",
    "        # The transformation of images is not under thread lock\n",
    "        # so it can be done in parallel\n",
    "        print(list(self.x.shape)[1:])\n",
    "        batch_x = np.zeros(\n",
    "            tuple([current_batch_size] + (1,) + list(self.x.shape)[1:]), dtype=K.floatx()) #Added +(1,) +\n",
    "        \n",
    "        batch_y = np.zeros(\n",
    "            tuple([current_batch_size]+(1,) + list(self.y.shape)[1:]), dtype=K.floatx()) #Added +(1,) +\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            x = self.x[j]\n",
    "            #x = self.image_data_generator.random_transform(x.astype(K.floatx()))\n",
    "            #x = self.image_data_generator.standardize(x)\n",
    "            x = self.image_data_generator.change_dims(x)  # my addition\n",
    "            batch_x[i] = x\n",
    "            \n",
    "            # need to check if it requirs or not for ground \n",
    "            y = self.y[j]\n",
    "            y = self.image_data_generator.change_dims(x)  # my addition\n",
    "            batch_y[i] = y\n",
    "            \n",
    "        return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(path, grayscale=False, target_size=None):\n",
    "    \"\"\"Loads an image into PIL format.\n",
    "    # Arguments\n",
    "        path: Path to image file\n",
    "        grayscale: Boolean, whether to load the image as grayscale.\n",
    "        target_size: Either `None` (default to original size)\n",
    "            or tuple of ints `(img_height, img_width)`.\n",
    "    # Returns\n",
    "        A PIL Image instance.\n",
    "    # Raises\n",
    "        ImportError: if PIL is not available.\n",
    "    \"\"\"\n",
    "    if pil_image is None:\n",
    "        raise ImportError('Could not import PIL.Image. '\n",
    "                          'The use of `array_to_img` requires PIL.')\n",
    "    img = pil_image.open(path)\n",
    "    if grayscale:\n",
    "        if img.mode != 'L':\n",
    "            img = img.convert('L')\n",
    "    else:\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "    if target_size:\n",
    "        hw_tuple = (target_size[1], target_size[0])\n",
    "        if img.size != hw_tuple:\n",
    "            img = img.resize(hw_tuple)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3386d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(img, data_format=None):\n",
    "    \"\"\"Converts a PIL Image instance to a Numpy array.\n",
    "    # Arguments\n",
    "        img: PIL Image instance.\n",
    "        data_format: Image data format.\n",
    "    # Returns\n",
    "        A 3D Numpy array.\n",
    "    # Raises\n",
    "        ValueError: if invalid `img` or `data_format` is passed.\n",
    "    \"\"\"\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format: ', data_format)\n",
    "    # Numpy array x has format (height, width, channel)\n",
    "    # or (channel, height, width)\n",
    "    # but original PIL image has format (width, height, channel)\n",
    "    x = np.asarray(img, dtype=K.floatx())\n",
    "    if len(x.shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.transpose(2, 0, 1)\n",
    "    elif len(x.shape) == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "        else:\n",
    "            x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "    else:\n",
    "        raise ValueError('Unsupported image shape: ', x.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03dbb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img):\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8311483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array_of_images(images):\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        #img = pil_image.open(images[i]).resize(IMG_SIZE)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(images[i]))\n",
    "        plt.title(i)\n",
    "        plt.axis('off')\n",
    "        plt.suptitle('ImageNet predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    #print(pred_mask.shape)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    #print(pred_mask.shape)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    #print(pred_mask.shape)\n",
    "    return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8806a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array_of_forground_mask(images):\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(create_mask(images[i])))\n",
    "        plt.title(i)\n",
    "        plt.axis('off')\n",
    "        plt.suptitle('ImageNet predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_array_of_images(images):\n",
    "    plt.figure(figsize=(10, 9))\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(2, 2, i + 1)\n",
    "        #img = pil_image.open(images[i]).resize(IMG_SIZE)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(images[i]))\n",
    "        plt.title(i)\n",
    "        plt.axis('off')\n",
    "        plt.suptitle('ImageNet predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DirectoryIterator(Iterator):\n",
    "    \n",
    "    def __init__(self,\n",
    "                directory,\n",
    "                image_data_generator,\n",
    "                target_size = IMG_SIZE,\n",
    "                frames_per_step = FRAMES_PER_STEP,\n",
    "                batch_size = BATCH_SIZE,\n",
    "                data_format = None,\n",
    "                seed = None):\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format\n",
    "        self.directory = directory\n",
    "        self.frames_per_step = frames_per_step\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.data_format = data_format\n",
    "        ## Need to handle data_format here. check code\n",
    "        \n",
    "        self.samples = 0\n",
    "        \n",
    "        classes = []\n",
    "        for subdir in sorted(os.listdir(directory)):\n",
    "            if os.path.isdir(os.path.join(directory, subdir)):\n",
    "                classes.append(subdir)\n",
    "        #print(classes)\n",
    "        self.num_class = len(classes)\n",
    "        # first, count the number of samples and classes\n",
    "            \n",
    "        #print(self.num_class)\n",
    "        self.class_indices = dict(zip(classes, range(self.num_class)))\n",
    "        #print(self.class_indices)\n",
    "        \n",
    "        pool = multiprocessing.pool.ThreadPool()\n",
    "        function_partial = partial(count_valid_files_in_directory,\n",
    "                                   follow_links=False)\n",
    "        \n",
    "        self.samples = sum(pool.map(function_partial, (os.path.join(directory, subdir) for subdir in classes)))\n",
    "        \n",
    "        print('Found %d images belonging to %d classes.' %\n",
    "              (self.samples, self.num_class))\n",
    "        \n",
    "        # second, build an index of the images in the different class subfolders\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        self.input_files = []\n",
    "        self.groundtruth_files = []\n",
    "        self.classes = np.zeros((self.samples,), dtype='int32')\n",
    "        #print(self.classes)\n",
    "        #i = 0\n",
    "        for dirpath in (os.path.join(directory, subdir) for subdir in classes):\n",
    "            results.append(pool.apply_async(list_valid_filenames_in_directory,\n",
    "                                            (dirpath, False)))\n",
    "            \n",
    "        for res in results:\n",
    "            input_file, groundtruth_file = res.get()\n",
    "            self.input_files += input_file\n",
    "            self.groundtruth_files += groundtruth_file\n",
    "            #i += len(input_file)\n",
    "        #print(self.input_files)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        super(DirectoryIterator, self).__init__(self.samples, batch_size, frames_per_step, seed)\n",
    "        \n",
    "    def next(self):\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        #print('index array', index_array)\n",
    "        #print('current_batch_size',current_batch_size)\n",
    "        #print()\n",
    "        \n",
    "        # the transformation of images is not under the thread lock so it can be done in paraller\n",
    "        #images = []\n",
    "        batch_x = np.zeros((current_batch_size,) + (self.frames_per_step,) + IMG_SIZE + (3,), dtype=K.floatx())\n",
    "        batch_y = np.zeros((current_batch_size,) + (self.frames_per_step,) + IMG_SIZE + (1,), dtype=K.floatx())\n",
    "        for xx in range(self.frames_per_step):\n",
    "        #for kk in range(1):\n",
    "            for index in range(int(len(index_array)/self.frames_per_step)):\n",
    "            #for i in range(1):\n",
    "                #print('total count================',len(self.input_files))\n",
    "                #print('index ================',(index + (xx * BATCH_SIZE)))\n",
    "                #print('input file size',len(self.input_files))\n",
    "                #print('index', index)\n",
    "                #print('xx', xx)\n",
    "                #print('index_array', index_array[index + (xx * BATCH_SIZE)]) \n",
    "                #print('calculated index', index + (xx * BATCH_SIZE))\n",
    "                \n",
    "                if len(index_array)> (index + (xx * BATCH_SIZE)):\n",
    "                    \n",
    "                    fname = self.input_files[index_array[index + (xx * BATCH_SIZE)]]\n",
    "                    #fname = self.input_files[index_array[index]]\n",
    "                    #img = pil_image.open(fname).resize(IMG_SIZE)\n",
    "                    #print('x->',index)\n",
    "                    img = load_img(fname, grayscale=False, target_size= IMG_SIZE)\n",
    "                    #images.append(img)\n",
    "                    x = img_to_array(img, data_format= self.data_format)\n",
    "                    x /= 255.0\n",
    "                    #x.shape\n",
    "                    batch_x[index, xx] = x\n",
    "                \n",
    "        for yy in range(self.frames_per_step):\n",
    "        #for kk in range(1):\n",
    "            for index in range(int(len(index_array)/self.frames_per_step)):\n",
    "            #for i in range(1):\n",
    "                if len(index_array)> (index + (yy * BATCH_SIZE)):\n",
    "                    fname = self.groundtruth_files[index_array[index + (yy * BATCH_SIZE)]]\n",
    "                    #fname = self.groundtruth_files[index_array[index]]\n",
    "                    #img = pil_image.open(fname).resize(IMG_SIZE)\n",
    "                    img = load_img(fname, grayscale=True, target_size= IMG_SIZE)\n",
    "                    #images.append(img)\n",
    "                    y = img_to_array(img, data_format= self.data_format)\n",
    "                    y /= 255.0 \n",
    "                    #x.shape\n",
    "                    batch_y[index, yy] = y\n",
    "        return batch_x, batch_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e9e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_valid_files_in_directory(directory, follow_links):\n",
    "    def count_file(subdir):\n",
    "        samples = 0\n",
    "        arr = sorted(os.listdir(subdir))\n",
    "        for files in arr:\n",
    "            is_valid = False \n",
    "            for extension in ['png', 'jpg', 'jpeg']:\n",
    "                if files.lower().endswith('.' + extension):\n",
    "                    is_valid = True\n",
    "                    break\n",
    "            if is_valid:\n",
    "                samples += 1\n",
    "        return samples\n",
    "    \n",
    "    input_file_path = directory + '/input'\n",
    "    #groundtruth_file_path = directory + '/groundtruth'\n",
    "    input_samples = count_file(input_file_path)\n",
    "   # groundtruth_samples = count_file(groundtruth_file_path)\n",
    "    return input_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6deaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_valid_filenames_in_directory(directory, follow_links):\n",
    "    input_names = []\n",
    "    groundtruth_names = []\n",
    "    input_file_path = directory + '/input'\n",
    "    arr = sorted(os.listdir(input_file_path))\n",
    "    for fname in arr:\n",
    "        is_valid = False \n",
    "        for extension in ['png', 'jpg', 'jpeg']:\n",
    "            if fname.lower().endswith('.' + extension):\n",
    "                is_valid = True\n",
    "                break\n",
    "        if is_valid:\n",
    "            #classes.append(class_indices[subdir])\n",
    "            # add filename relative to directory\n",
    "            input_names.append(os.path.join(input_file_path, fname))\n",
    "            \n",
    "    groundtruth_file_path = directory + '/groundtruth'\n",
    "    arr = sorted(os.listdir(groundtruth_file_path))\n",
    "    for fname in arr:\n",
    "        is_valid = False \n",
    "        for extension in ['png', 'jpg', 'jpeg']:\n",
    "            if fname.lower().endswith('.' + extension):\n",
    "                is_valid = True\n",
    "                break\n",
    "        if is_valid:\n",
    "            #classes.append(class_indices[subdir])\n",
    "            # add filename relative to directory\n",
    "            groundtruth_names.append(os.path.join(groundtruth_file_path, fname))\n",
    "    return input_names, groundtruth_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474661d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data_path = \"\\\\Users\\\\bchau\\\\Projects\\\\Thesis\\\\train_dataset\\\\badWeather\"\n",
    "validation_data_path = \"\\\\Users\\\\bchau\\\\Projects\\\\Thesis\\\\validation_dataset\\\\badWeather\"\n",
    "\n",
    "                \n",
    "train_gen = ImageDataGenerator()\n",
    "train_data = train_gen.flow_from_directory(train_data_path, target_size= IMG_SIZE, frames_per_step=FRAMES_PER_STEP, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_gen = ImageDataGenerator()\n",
    "validation_data = validation_gen.flow_from_directory(validation_data_path, target_size= IMG_SIZE, frames_per_step=FRAMES_PER_STEP, batch_size=BATCH_SIZE)\n",
    "\n",
    "STEPS_PER_EPOCH = train_data.samples // BATCH_SIZE\n",
    "\n",
    "VALIDATION_STEPS_PER_EPOCH = validation_data.samples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a3f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batch = train_data.next()\n",
    "input_img = train_data_batch[0][3]\n",
    "show_array_of_images(input_img)\n",
    "\n",
    "ground_img = train_data_batch[1][3]\n",
    "show_array_of_images(ground_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6359775",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = [FRAMES_PER_STEP, 240, 320, 3]\n",
    "model = Models.ecoder_decoder_cnn_lstm(input_dim, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss= 'binary_crossentropy',\n",
    "              metrics=[tf.keras.metrics.Accuracy(),\n",
    "                        tf.keras.metrics.Recall(), \n",
    "                        tf.keras.metrics.Precision(), \n",
    "                        tf.keras.metrics.FalseNegatives(),\n",
    "                        tf.keras.metrics.FalsePositives(), \n",
    "                        tf.keras.metrics.TrueNegatives(), \n",
    "                        tf.keras.metrics.TruePositives()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3575b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The callback define below is used to observe how the model improves while it is training.\n",
    "class DisplayCallback(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "        \n",
    "#Define TensorBoard callback here\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir,\n",
    "                                   histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_history = model.fit(train_data,\n",
    "          epochs=500,\n",
    "          validation_data=validation_data,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          validation_steps=VALIDATION_STEPS_PER_EPOCH,\n",
    "          verbose=1, callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot recall over precision here.\n",
    "\n",
    "recall = model_history.history['recall']\n",
    "precision = model_history.history['precision']\n",
    "plt.figure()\n",
    "plt.step(recall, precision, where='post' )\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlim((0, 1))\n",
    "plt.ylim((0, 1))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba036d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot overall accuracy of the model\n",
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "acc = model_history.history['accuracy']\n",
    "val_acc = model_history.history['val_accuracy']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
    "plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model_history.epoch, acc, 'r', label='Training loss')\n",
    "plt.plot(model_history.epoch, val_acc, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68534448",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172079fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions():\n",
    "    # Load unseen data for forground extraction \n",
    "    test_data_path = \"\\\\Users\\\\bchau\\\\Projects\\\\Thesis\\\\test_dataset\\\\badWeather\"\n",
    "    test_gen = ImageDataGenerator()\n",
    "    test_data = test_gen.flow_from_directory(test_data_path, target_size= IMG_SIZE, frames_per_step=FRAMES_PER_STEP, batch_size=BATCH_SIZE)\n",
    "    test_samples = test_data.next()\n",
    "    \n",
    "    # predict forground by passing the test data.\n",
    "    predictions = model.predict(test_samples[0], batch_size=BATCH_SIZE, steps=None, verbose=1)\n",
    "    predicted_img = predictions[3]\n",
    "    \n",
    "    # plot score map of forground\n",
    "    show_array_of_images(predicted_img)\n",
    "    \n",
    "    # plot output of forground\n",
    "    show_array_of_forground_mask(predicted_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
